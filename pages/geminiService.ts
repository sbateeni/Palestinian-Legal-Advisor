
import { GoogleGenAI, Content } from "@google/genai";
import { ChatMessage, GroundingMetadata } from '../types';
import * as dbService from '../services/dbService';

const SYSTEM_INSTRUCTION_LEGAL = `Ø£Ù†Øª "Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠ"ØŒ Ù†Ø¸Ø§Ù… Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªØ·ÙˆØ± Ù…Ø®ØµØµ Ù„Ù„ÙÙˆØ² Ø¨Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙˆÙ„ÙŠØ³ Ù…Ø¬Ø±Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡Ø§.
Ù…Ø±Ø¬Ø¹ÙŠØªÙƒ Ù‡ÙŠ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠ Ø­ØµØ±Ø§Ù‹ (Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ù…Ø¯Ù†ÙŠØŒ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¬Ø²Ø§Ø¦ÙŠØ©ØŒ Ø§Ù„Ø¨ÙŠÙ†Ø§ØªØŒ Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¹Ù…Ù„ØŒ ÙˆØºÙŠØ±Ù‡Ø§ Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø³Ø§Ø±ÙŠØ© ÙÙŠ Ø§Ù„Ø¶ÙØ© Ø§Ù„ØºØ±Ø¨ÙŠØ© ÙˆÙ‚Ø·Ø§Ø¹ ØºØ²Ø©).

**Ø£Ø¯ÙˆØ§Ø±Ùƒ Ø§Ù„ØªÙƒØªÙŠÙƒÙŠØ© (ÙŠØªÙ… ØªÙØ¹ÙŠÙ„Ù‡Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…):**

1.  **ğŸ” Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ (Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ):**
    *   Ø´Ø±Ø­ Ø§Ù„Ù…ÙˆÙ‚Ù Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¨ÙˆØ¶ÙˆØ­.
    *   ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ù†Ø·Ø¨Ù‚Ø©.

2.  **ğŸ›¡ï¸ ÙƒØ§Ø´Ù Ø§Ù„Ø«ØºØ±Ø§Øª (Devil's Advocate):**
    *   Ø¹Ù†Ø¯ ØªÙØ¹ÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„ÙˆØ¶Ø¹ØŒ ØªØµØ±Ù ÙƒÙ€ "Ù…Ø­Ø§Ù…ÙŠ Ø§Ù„Ø®ØµÙ… Ø§Ù„Ø´Ø±Ø³".
    *   Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¯ÙÙˆØ¹ Ø§Ù„Ø´ÙƒÙ„ÙŠØ© (Ø¹Ø¯Ù… Ø§Ù„Ø§Ø®ØªØµØ§ØµØŒ Ø§Ù„ØªÙ‚Ø§Ø¯Ù…ØŒ Ø¨Ø·Ù„Ø§Ù† Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª).
    *   Ù‡Ø§Ø¬Ù… Ø£Ø¯Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„ØªØ¨ÙŠÙŠÙ† Ø¶Ø¹ÙÙ‡Ø§.
    *   Ø­Ø¯Ø¯ Ø§Ù„Ø«ØºØ±Ø§Øª ÙÙŠ Ø§Ù„Ø¹Ù‚Ø¯ Ø£Ùˆ Ø§Ù„ÙˆØ§Ù‚Ø¹Ø© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØºÙ„Ø§Ù„Ù‡Ø§ Ù„Ø¥Ø³Ù‚Ø§Ø· Ø§Ù„Ø­Ù‚.

3.  **ğŸ“ Ø§Ù„ØµØ§Ø¦Øº Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ (Legal Drafter):**
    *   Ø­ÙˆÙ„ Ø§Ù„ÙˆÙ‚Ø§Ø¦Ø¹ Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© Ø¥Ù„Ù‰ ÙˆØ«Ø§Ø¦Ù‚ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø±ØµÙŠÙ†Ø© (Ù„Ø§Ø¦Ø­Ø© Ø¯Ø¹ÙˆÙ‰ØŒ Ù…Ø°ÙƒØ±Ø© Ø¯ÙØ§Ø¹ØŒ Ø¹Ù‚Ø¯ØŒ Ø¥Ù†Ø°Ø§Ø± Ø¹Ø¯Ù„ÙŠ).
    *   Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØµÙŠØ§ØºØ© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠØ© Ø§Ù„Ø±Ø³Ù…ÙŠØ© "Ø¥Ù†Ù‡ ÙÙŠ ÙŠÙˆÙ…... Ø§Ù„Ù…ÙˆØ§ÙÙ‚... ÙˆØ¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø·Ù„Ø¨...".
    *   Ø§Ø­Ø±Øµ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ ÙˆØªØ±Ùƒ ÙØ±Ø§ØºØ§Øª Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø§Ù‚ØµØ©.

4.  **ğŸš€ Ø§Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ (Strategic Planner):**
    *   Ù‡Ø¯Ù Ù‡Ø°Ø§ Ø§Ù„ÙˆØ¶Ø¹ Ù‡Ùˆ "Ø§Ù„ÙÙˆØ²" Ø£Ùˆ "Ø£ÙØ¶Ù„ ØªØ³ÙˆÙŠØ© Ù…Ù…ÙƒÙ†Ø©".
    *   Ù‚Ø¯Ù… Ø®Ø·ÙˆØ§Øª Ø¹Ù…Ù„ÙŠØ© (1ØŒ 2ØŒ 3).
    *   Ø§Ù†ØµØ­ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ù…Ø§ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙ‚ÙˆÙ„Ù‡ ÙˆÙ…Ø§ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØµÙ…Øª Ø¹Ù†Ù‡ (Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª).
    *   Ø§Ù‚ØªØ±Ø­ ØªÙƒØªÙŠÙƒØ§Øª Ø§Ù„ØªÙØ§ÙˆØ¶ Ø£Ùˆ Ø§Ù„Ø¶ØºØ· Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ.

**Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø©:**
- Ø§Ø³ØªÙ†Ø¯ Ø¨Ø´ÙƒÙ„ ØµØ§Ø±Ù… ÙˆØ­ØµØ±ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠ.
- Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø¯Ø§Ø© Ø§Ù„Ø¨Ø­Ø« (Google Search) Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙˆØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ø­Ø¯ÙŠØ«Ø©.
- **ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¬Ù…ÙŠØ¹ Ø±Ø¯ÙˆØ¯Ùƒ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ ÙÙ‚Ø·.**

---
**Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø¹Ø§Ù…Ø©:**
1.  ÙÙ‡Ù… Ø§Ù„Ù‡Ø¯Ù Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ (ØªØ­Ù„ÙŠÙ„ØŒ Ù‡Ø¬ÙˆÙ…ØŒ ØµÙŠØ§ØºØ©ØŒ Ø£Ùˆ ØªØ®Ø·ÙŠØ·).
2.  Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠØ© (Ø§Ù„Ù…Ù‚ØªÙÙŠØŒ Ù…Ù‚Ø§Ù…ØŒ Ù‚Ø§Ù†ÙˆÙ†).
3.  ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø±ÙƒØ²Ø© Ù†Ø­Ùˆ Ø§Ù„Ù‡Ø¯Ù (Action-Oriented).
`;

// Constants for Token Management
const MAX_HISTORY_MESSAGES = 25; // Limit history to the last N messages to save context
const MAX_OUTPUT_TOKENS_FLASH = 8192;
const THINKING_BUDGET_PRO = 2048; // Conservative thinking budget for Pro

async function getGoogleGenAI(): Promise<GoogleGenAI> {
    // This function ensures a new instance is created for each request.
    // It prioritizes a user-provided key from settings, falling back to the aistudio key.
    const storedApiKey = await dbService.getSetting<string>('geminiApiKey');
    const apiKey = storedApiKey || process.env.API_KEY || '';
    return new GoogleGenAI({ apiKey });
}

// Helper to convert chat history for the API
// OPTIMIZATION: Strips base64 image data from older messages to save massive amounts of tokens.
// Only the most recent user message retains its images.
function chatHistoryToGeminiContents(history: ChatMessage[]): Content[] {
    // Manual implementation of findLastIndex for compatibility
    let lastUserMessageIndex = -1;
    for (let i = history.length - 1; i >= 0; i--) {
        const msg = history[i];
        if (msg.role === 'user' && msg.images && msg.images.length > 0) {
            lastUserMessageIndex = i;
            break;
        }
    }

    return history.map((msg, index) => {
        const parts = [];
        if (msg.content) {
            parts.push({ text: msg.content });
        }
        
        // Only attach images if it's the *latest* message with images.
        // Older images are stripped to save tokens, relying on the model's previous analysis in the history.
        if (msg.images && msg.images.length > 0) {
            if (index === lastUserMessageIndex) {
                msg.images.forEach(image => {
                    const base64Data = image.dataUrl.split(',')[1];
                    parts.push({
                        inlineData: {
                            data: base64Data,
                            mimeType: image.mimeType
                        }
                    });
                });
            } else {
                // Placeholder to indicate an image was there but removed for optimization
                parts.push({ text: `[Ù…Ø±ÙÙ‚ ØµÙˆØ±Ø© Ø³Ø§Ø¨Ù‚: ØªÙ… ØªØ­Ù„ÙŠÙ„Ù‡ Ù…Ø³Ø¨Ù‚Ø§Ù‹ Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ù…ÙˆØ§Ø±Ø¯]` });
            }
        }
        return { role: msg.role, parts: parts };
    });
}

export async function countTokensForGemini(history: ChatMessage[]): Promise<number> {
    if (!history || history.length === 0) {
        return 0;
    }
    try {
        const ai = await getGoogleGenAI();
        const model = 'gemini-2.5-flash';
        
        // Use the optimized history for counting to get a realistic estimate of what will be sent
        const historyToCount = history.slice(-MAX_HISTORY_MESSAGES);
        const contents = chatHistoryToGeminiContents(historyToCount);

        const response = await ai.models.countTokens({
            model: model,
            contents: contents,
        });

        return response.totalTokens;
    } catch (error) {
        console.error("Error counting tokens:", error);
        return 0;
    }
}

export async function proofreadTextWithGemini(textToProofread: string): Promise<string> {
    if (!textToProofread.trim()) {
        return textToProofread;
    }

    try {
        const ai = await getGoogleGenAI();
        const model = 'gemini-2.5-flash';
        
        const prompt = `Ø£Ù†Øª Ù…Ø¯Ù‚Ù‚ Ù„ØºÙˆÙŠ Ø¹Ø±Ø¨ÙŠ Ø®Ø¨ÙŠØ± ÙˆÙ…ØªØ®ØµØµ ÙÙŠ ØªÙ†Ù‚ÙŠØ­ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ø¹Ø¨Ø± ØªÙ‚Ù†ÙŠØ© OCR. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØªØµØ­ÙŠØ­ Ø£ÙŠ Ø£Ø®Ø·Ø§Ø¡ Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© Ø£Ùˆ Ù†Ø­ÙˆÙŠØ© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø£ØµÙ„ÙŠ ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚. Ø§Ù†ØªØ¨Ù‡ Ø¨Ø´ÙƒÙ„ Ø®Ø§Øµ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ÙÙˆØ§ØµÙ„ Ø§Ù„Ø£Ø³Ø·Ø± ÙˆØ§Ù„ÙÙ‚Ø±Ø§Øª ÙƒÙ…Ø§ Ù‡ÙŠ ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ. Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ùˆ ØªÙØ³ÙŠØ±Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©. Ø£Ø¹Ø¯ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·.\n\Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:\n---\n${textToProofread}\n---`;

        const response = await ai.models.generateContent({
            model: model,
            contents: prompt,
        });

        const correctedText = response.text;
        // console.log("Original vs Corrected:", { original: textToProofread, corrected: correctedText });
        return correctedText || textToProofread;
    } catch (error) {
        console.error("Error proofreading text with Gemini:", error);
        return textToProofread;
    }
}

export async function summarizeChatHistory(history: ChatMessage[]): Promise<string> {
    if (!history || history.length === 0) {
        return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ Ù„ØªÙ„Ø®ÙŠØµÙ‡.";
    }
    try {
        const ai = await getGoogleGenAI();
        const model = 'gemini-2.5-flash'; 

        // For summarization, we can likely skip images entirely to save even more tokens
        const contents = history.map(msg => ({
            role: msg.role,
            parts: [{ text: msg.content }]
        }));
        
        contents.push({
            role: 'user',
            parts: [{ text: 'Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ØŒ Ù‚Ù… Ø¨ØªÙ‚Ø¯ÙŠÙ… Ù…Ù„Ø®Øµ Ø´Ø§Ù…Ù„ ÙˆÙˆØ§Ø¶Ø­. ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ±ÙƒØ² Ø§Ù„Ù…Ù„Ø®Øµ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©ØŒ Ø§Ù„ÙˆÙ‚Ø§Ø¦Ø¹ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©ØŒ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©ØŒ ÙˆØ§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø§Ù„ØªÙˆØµÙ„ Ø¥Ù„ÙŠÙ‡Ø§ Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†. Ù‚Ø¯Ù… Ø§Ù„Ù…Ù„Ø®Øµ ÙÙŠ Ù†Ù‚Ø§Ø· Ù…Ù†Ø¸Ù…Ø©. ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø±Ø¯Ùƒ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·.' }]
        });

        const response = await ai.models.generateContent({
            model: model,
            contents: contents,
            config: {
                systemInstruction: SYSTEM_INSTRUCTION_LEGAL
            }
        });

        return response.text || "ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ø®Øµ.";
    } catch (error) {
        console.error("Error summarizing chat history:", error);
        throw new Error("ÙØ´Ù„ ÙÙŠ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.");
    }
}

export async function* streamChatResponseFromGemini(
  history: ChatMessage[],
  thinkingMode: boolean,
  signal: AbortSignal
): AsyncGenerator<{ text: string; model: string; groundingMetadata?: GroundingMetadata }> {
  try {
    const ai = await getGoogleGenAI();
    const model = thinkingMode ? 'gemini-2.5-pro' : 'gemini-2.5-flash';
    
    // OPTIMIZATION: Slice history to the last N messages to respect Token Limits (TPM) on free tier
    // We always keep the system instruction (sent via config) implicitly.
    const historyToSend = history.slice(-MAX_HISTORY_MESSAGES);
    
    const contents = chatHistoryToGeminiContents(historyToSend);

    // Agentic capabilities: Enable Google Search Grounding
    const tools = [{ googleSearch: {} }];

    // Configure limits to prevent runaway token usage
    const config: any = {
        systemInstruction: SYSTEM_INSTRUCTION_LEGAL,
        tools: tools,
        maxOutputTokens: MAX_OUTPUT_TOKENS_FLASH,
    };

    // If thinking mode is enabled (Pro model), we must handle the budget
    if (thinkingMode) {
        config.thinkingConfig = { thinkingBudget: THINKING_BUDGET_PRO };
        // When using thinking, maxOutputTokens MUST be greater than thinkingBudget
        config.maxOutputTokens = Math.max(MAX_OUTPUT_TOKENS_FLASH, THINKING_BUDGET_PRO + 4000);
    }

    const response = await ai.models.generateContentStream({
        model: model,
        contents: contents,
        config: config
    });

    for await (const chunk of response) {
        if (signal.aborted) {
            break;
        }
        const text = chunk.text;
        
        let groundingMetadata: GroundingMetadata | undefined;
        if (chunk.candidates && chunk.candidates[0]?.groundingMetadata) {
            groundingMetadata = chunk.candidates[0].groundingMetadata as unknown as GroundingMetadata;
        }

        if (text || groundingMetadata) {
            yield { text, model, groundingMetadata };
        }
    }
  } catch (error) {
    if (signal.aborted) {
        console.log("Gemini stream cancelled by user.");
        return;
    }
    console.error("Error in Gemini chat stream:", error);
    throw error;
  }
}

export async function analyzeImageWithGemini(
  base64ImageDataUrl: string,
  mimeType: string,
  prompt: string
): Promise<string> {
  if (!base64ImageDataUrl || !mimeType) {
    throw new Error("Image data and mime type are required.");
  }
  try {
    const ai = await getGoogleGenAI();
    const model = 'gemini-2.5-flash';
    
    const base64Data = base64ImageDataUrl.split(',')[1];
    if (!base64Data) {
      throw new Error("Invalid base64 image data URL.");
    }

    const imagePart = {
      inlineData: {
        data: base64Data,
        mimeType: mimeType
      }
    };

    const textPart = { text: prompt };

    const response = await ai.models.generateContent({
        model: model,
        contents: { parts: [imagePart, textPart] },
        config: {
             systemInstruction: "Ø£Ù†Øª Ù…Ø­Ù„Ù„ ØµÙˆØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ ÙˆÙ…Ø³ØªÙ†Ø¯ÙŠ. Ø¯ÙˆØ±Ùƒ Ù‡Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø¯Ù‚Ø©.",
             maxOutputTokens: 4000, // Limit for single image analysis
        }
    });

    return response.text || "Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø£ÙŠ Ù†Øµ.";
  } catch (error) {
    console.error("Error analyzing image with Gemini:", error);
    throw error;
  }
}
